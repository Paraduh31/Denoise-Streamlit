# -*- coding: utf-8 -*-
"""draftcnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HZsw3dJkc3qFsJtfoDLhRQD6ePiDPA7U

# **IMPORT LIBRARIES AND INPUT FUNCTIONS**
"""

import numpy as np
import cv2
import glob
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import os
import imageio.v2 as imageio
from skimage import color
import random
from scipy import stats

def load_image(file):
    image = imageio.imread(file)
    image = tf.image.convert_image_dtype(image, tf.float32)  # Normalize to [0,1]
    return image

def data_generator(high_files, low_files, batch_size):
    dataset_size = len(high_files)
    for i in range(0, dataset_size, batch_size):
        batch_high = [load_image(f) for f in high_files[i:i+batch_size]]
        batch_low = [load_image(f) for f in low_files[i:i+batch_size]]
        yield np.array(batch_low), np.array(batch_high)

"""# CREATE DATASET PATHS"""

base_path = '/kaggle/input/loldataset/LOLdataset'
train_high_path = os.path.join(base_path, 'train/high')
train_low_path = os.path.join(base_path, 'train/low')
val_high_path = os.path.join(base_p ath, 'val/high')
val_low_path = os.path.join(base_path, 'val/low')

# Load file paths
high_files = sorted(glob.glob(train_high_path + "/*.png"))
low_files = sorted(glob.glob(train_low_path + "/*.png"))
high_val_files = sorted(glob.glob(val_high_path + "/*.png"))
low_val_files = sorted(glob.glob(val_low_path + "/*.png"))

# batch size
batch_size = 16

"""# Create training dataset

"""

dataset_train = tf.data.Dataset.from_generator(
    lambda: data_generator(high_files, low_files, batch_size),
    output_signature=(
        tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),
        tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32)
    )
).prefetch(tf.data.AUTOTUNE)

# Create validation dataset
dataset_val = tf.data.Dataset.from_generator(
    lambda: data_generator(high_val_files, low_val_files, batch_size),
    output_signature=(
        tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),
        tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32)
    )
).prefetch(tf.data.AUTOTUNE)

"""CHECKER"""

# Print number of training samples
print(f"Training samples: {len(high_files)}")
print(f"Validation samples: {len(high_val_files)}")

# Display a batch sample
for low_batch, high_batch in dataset_train.take(1):
    plt.figure(figsize=(20,10))
    plt.subplot(1,2,1)
    plt.title("Ground Truth (High Light)", fontsize=20)
    plt.imshow(high_batch[1])

    plt.subplot(1,2,2)
    plt.title("Input (Low Light)", fontsize=20)
    plt.imshow(low_batch[1])
    plt.savefig('sample_comparison.png')
    plt.show()
    break

"""**DEFINING EVALUATION FUNCTION**

"""

# Define PSNR metric
def psnr_metric(y_true, y_pred):
    return tf.image.psnr(y_true, y_pred, max_val=1.0)

def load_images_from_files(file_list):
    images = []
    for file in file_list:
        img = imageio.imread(file)
        # Convert to float32 and normalize to [0,1]
        img = img.astype('float32') / 255.0
        images.append(img)
    return np.array(images)

print("Loading training images...")
high_images = load_images_from_files(high_files)
low_images = load_images_from_files(low_files)

print("Loading validation images...")
high_val = load_images_from_files(high_val_files)
low_val = load_images_from_files(low_val_files)

low_train_norm = low_images
high_train_norm = high_images
low_val_norm = low_val
high_val_norm = high_val

if len(high_images) > 0 and len(low_images) > 0:
    # Removed additional normalization step since images are already in [0,1]

    if len(high_val) == 0 or len(low_val) == 0:
        print("No validation data available. Using a portion of training data for validation.")
        val_split = 0.1
        val_indices = np.random.choice(len(high_images), int(len(high_images) * val_split), replace=False)

        high_val_norm = high_train_norm[val_indices]
        low_val_norm = low_train_norm[val_indices]

        train_mask = np.ones(len(high_images), dtype=bool)
        train_mask[val_indices] = False
        high_train_norm = high_train_norm[train_mask]
        low_train_norm = low_train_norm[train_mask]

    print("Low train shape:", low_train_norm.shape)
    print("High train shape:", high_train_norm.shape)
    print("Low val shape:", low_val_norm.shape)
    print("High val shape:", high_val_norm.shape)

print("Training data range:", low_train_norm.min(), low_train_norm.max())
print("Validation data range:", low_val_norm.min(), low_val_norm.max())

"""**DATA PREPROCESSING**"""

print("Training data range:", low_train_norm.min(), low_train_norm.max())
print("Validation data range:", low_val_norm.min(), low_val_norm.max())



# Create a custom data generator
    class ImageDenoiseGenerator(tf.keras.utils.Sequence):
        def __init__(self, X, y, batch_size=4):
            self.X = X
            self.y = y
            self.batch_size = batch_size

        def __len__(self):
            return len(self.X) // self.batch_size

        def __getitem__(self, idx):
            # Get batch indices
            start_idx = idx * self.batch_size
            end_idx = min((idx + 1) * self.batch_size, len(self.X))

            # Extract batch
            X_batch = self.X[start_idx:end_idx]
            y_batch = self.y[start_idx:end_idx]

            return X_batch, y_batch

    # Create model
    activation = 'relu'
    padding = 'same'
    kernel = (3,3)

    inputs = keras.Input(shape=(None, None, 3), name='img')

    layer1 = layers.Conv2D(32, kernel, activation=activation, padding=padding)(inputs)
    layer2 = layers.Conv2D(32, kernel, activation=activation, padding=padding)(layer1)
    layer3 = layers.Conv2D(32, kernel, activation=activation, padding=padding)(layer2)
    layer4 = layers.Conv2D(32, kernel, activation=activation, padding=padding)(layer3)
    layer5 = layers.add([layer3, layer4])  # Combination of 2 layers
    layer6 = layers.Conv2D(32, kernel, activation=activation, padding=padding)(layer5)
    layer7 = layers.add([layer2, layer6])  # combination of 2 layers
    layer8 = layers.Conv2D(32, kernel, activation=activation, padding=padding)(layer7)
    final = layers.add([layer1, layer8])

    outLayer = layers.Conv2D(3, kernel, activation='sigmoid', padding=padding)(final)

    denoisingModel = keras.Model(inputs, outLayer)

    denoisingModel.compile(
        optimizer='adam',
        loss='mse',
        metrics=[psnr_metric]
    )

    denoisingModel.summary()

    # Create training generator
    training_generator = ImageDenoiseGenerator(low_train_norm, high_train_norm, batch_size=4)
    validation_generator = ImageDenoiseGenerator(low_val_norm, high_val_norm, batch_size=4)

    X_sample, y_sample = training_generator[0]
    print("X sample shape:", X_sample.shape)
    print("Y sample shape:", y_sample.shape)

    history = denoisingModel.fit(
        training_generator,
        validation_data=validation_generator,
        epochs=20,
        verbose=1
    )

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss over Epochs')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['psnr_metric'], label='Training PSNR')
    plt.plot(history.history['val_psnr_metric'], label='Validation PSNR')
    plt.title('PSNR over Epochs')
    plt.xlabel('Epoch')
    plt.ylabel('PSNR (dB)')
    plt.legend()
    plt.tight_layout()
    plt.savefig('training_history.png')
    plt.show()

"""**VALIDATION AND TESTING**"""



def visualize_results(model, low_images, high_images, num_samples=3):
    plt.figure(figsize=(15, 5*num_samples))

    indices = np.random.choice(len(low_images), size=min(num_samples, len(low_images)), replace=False)

    for i, idx in enumerate(indices):
        low_img = low_images[idx:idx+1]
        high_img = high_images[idx:idx+1]

        pred = model.predict(low_img)

        low_img_vis = low_img[0]
        high_img_vis = high_img[0]
        pred_vis = pred[0]

        psnr_value = tf.image.psnr(high_img, pred, max_val=1.0).numpy()[0]

        # Display
        plt.subplot(num_samples, 3, i*3+1)
        plt.title("Low Light Input")
        plt.imshow(low_img_vis)

        plt.subplot(num_samples, 3, i*3+2)
        plt.title(f"Model Output (PSNR: {psnr_value:.2f} dB)")
        plt.imshow(pred_vis)

        plt.subplot(num_samples, 3, i*3+3)
        plt.title("Ground Truth")
        plt.imshow(high_img_vis)

    plt.tight_layout()
    plt.savefig('results_comparison.png')
    plt.show()

# Calculate PSNR for validation set
def calculate_psnr_for_dataset(model, low_images, high_images):
    psnr_values = []

    for i in range(len(low_images)):
        low_img = low_images[i:i+1]
        high_img = high_images[i:i+1]

        pred = model.predict(low_img, verbose=0)

        # Calculate PSNR
        psnr = tf.image.psnr(high_img, pred, max_val=1.0).numpy()[0]
        psnr_values.append(psnr)

    return np.mean(psnr_values), np.std(psnr_values)

visualize_results(denoisingModel, low_val_norm, high_val_norm, num_samples=3)

mean_psnr, std_psnr = calculate_psnr_for_dataset(denoisingModel, low_val_norm, high_val_norm)
print(f"Validation PSNR: {mean_psnr:.2f} Â± {std_psnr:.2f} dB")

denoisingModel.save('/kaggle/working/denoising_model.h5')
print("Model saved to /kaggle/working/denoising_model.h5")


sample_indices = np.random.choice(len(low_val_norm), size=min(5, len(low_val_norm)), replace=False)

for i, idx in enumerate(sample_indices):
    plt.figure(figsize=(15, 5))

    low_img = low_val_norm[idx:idx+1]
    high_img = high_val_norm[idx:idx+1]

    pred = denoisingModel.predict(low_img, verbose=0)

    plt.subplot(1, 3, 1)
    plt.title("Low Light Input")
    plt.imshow(low_img[0])

    plt.subplot(1, 3, 2)
    plt.title("Model Output")
    plt.imshow(pred[0])

    plt.subplot(1, 3, 3)
    plt.title("Ground Truth")
    plt.imshow(high_img[0])

    plt.tight_layout()
    plt.savefig(f'/kaggle/working/result_sample_{i}.png')
    plt.close()

print("Results saved to working directory")